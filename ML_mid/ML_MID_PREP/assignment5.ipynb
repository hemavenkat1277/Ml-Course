{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44973127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cf5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_2572\\626770024.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(),inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare\n",
       "0         0       3    0 -0.592148      1      0 -0.502163\n",
       "1         1       1    1  0.638430      1      0  0.786404\n",
       "2         1       3    1 -0.284503      0      0 -0.488580\n",
       "3         1       1    1  0.407697      1      0  0.420494\n",
       "4         0       3    0  0.407697      0      0 -0.486064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('Titanic.csv')\n",
    "df.drop(['PassengerId','Name','Ticket','Cabin',\"Embarked\"],axis=1,inplace=True)\n",
    "df[\"Sex\"]=df['Sex'].map({\"male\":0, \"female\":1}).astype(int)\n",
    "df.head()\n",
    "\n",
    "df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "def Z_norm(col):\n",
    "    return (col-col.mean())/col.std()\n",
    "\n",
    "df['Age']=Z_norm(df['Age'])\n",
    "df['Fare']=Z_norm(df['Fare'])\n",
    "\n",
    "\n",
    "x = df.iloc[:, 1:5]\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412cf860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # Convert y to 1D numpy array if it's not already\n",
    "    y = np.array(y).flatten()\n",
    "    # Use np.bincount for integer labels\n",
    "    proportions = np.bincount(y) / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "\n",
    "def information_gain(X_column, y, threshold):\n",
    "    left_mask = X_column <= threshold\n",
    "    right_mask = X_column > threshold\n",
    "\n",
    "    if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "        return 0\n",
    "\n",
    "    parent_entropy = entropy(y)\n",
    "    n = len(y)\n",
    "    n_left, n_right = len(y[left_mask]), len(y[right_mask])\n",
    "\n",
    "    e_left = entropy(y[left_mask])\n",
    "    e_right = entropy(y[right_mask])\n",
    "\n",
    "    child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "    return parent_entropy - child_entropy\n",
    "\n",
    "# Now you can proceed with the rest of the code as before\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gain = -1\n",
    "    best_feature, best_threshold = None, None\n",
    "\n",
    "    for feature_idx in range(X.shape[1]):\n",
    "        thresholds = np.unique(X.iloc[:, feature_idx].values)\n",
    "        for threshold in thresholds:\n",
    "            gain = information_gain(X.iloc[:, feature_idx].values, y, threshold)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=None):\n",
    "    # Ensure y is a 1D numpy array\n",
    "    y = np.array(y).flatten()\n",
    "\n",
    "    # Base case: if all values are the same or max depth reached\n",
    "    if len(np.unique(y)) == 1 or (max_depth is not None and depth >= max_depth):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    feature, threshold = best_split(X, y)\n",
    "    if feature is None:\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    left_mask = X.iloc[:, feature].values <= threshold\n",
    "    right_mask = X.iloc[:, feature].values > threshold\n",
    "\n",
    "    left_subtree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
    "    right_subtree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
    "\n",
    "    return {\"feature\": feature, \"threshold\": threshold, \"left\": left_subtree, \"right\": right_subtree}\n",
    "\n",
    "def predict_sample(x, tree):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    feature, threshold = tree[\"feature\"], tree[\"threshold\"]\n",
    "    feature_value = x[feature]\n",
    "    if feature_value <= threshold:\n",
    "        return predict_sample(x, tree[\"left\"])\n",
    "    else:\n",
    "        return predict_sample(x, tree[\"right\"])\n",
    "    \n",
    "def predict(x,tree):\n",
    "    return np.array([predict_sample(inp,tree) for inp in x.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acada823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Function for bootstrap sampling\n",
    "def bootstrap_sample(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    X_sample = X.iloc[indices]\n",
    "    y_sample = y.iloc[indices]\n",
    "    return X_sample, y_sample\n",
    "\n",
    "def train_decision_tree(X_train, y_train, max_depth=None):\n",
    "    return build_tree(X_train, y_train, max_depth=max_depth)\n",
    "\n",
    "def predict_with_bagging(X, trees):\n",
    "    predictions = np.array([predict(X, tree) for tree in trees])\n",
    "    return [np.bincount(pred).argmax() for pred in predictions.T]\n",
    "\n",
    "def bagging(X_train, y_train, n_trees=10, max_depth=None):\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        X_sample, y_sample = bootstrap_sample(X_train, y_train)\n",
    "        tree = train_decision_tree(X_sample, y_sample,max_depth)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "130bfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 79.3296\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 79.3296\n",
      "Accuracy with Bagging: 79.3296\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 78.7709\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 78.7709\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 83.2402\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 78.7709\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 79.3296\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 79.3296\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.6816\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 80.4469\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 81.0056\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 82.1229\n",
      "Accuracy with Bagging: 79.8883\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.5642\n",
      "Accuracy with Bagging: 81.5642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(100):\n",
    "    x = df.iloc[:, 1:5]\n",
    "    y = df.iloc[:, :1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    colls=len(x.columns)-1\n",
    "    n_trees = colls**0.5\n",
    "    n_trees = int(n_trees)\n",
    "    max_depth = 5\n",
    "    trees = bagging(x_train, y_train, n_trees=n_trees, max_depth=max_depth)\n",
    "    \n",
    "    y_pred = predict_with_bagging(x_test, trees)\n",
    "    \n",
    "    accuracy = np.mean(y_pred == y_test.values.flatten())\n",
    "    print(f\"Accuracy with Bagging: {accuracy*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf82fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
