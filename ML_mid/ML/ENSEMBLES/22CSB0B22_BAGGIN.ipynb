{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44973127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cf5120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare\n",
       "0         0       3    0 -0.592148      1      0 -0.502163\n",
       "1         1       1    1  0.638430      1      0  0.786404\n",
       "2         1       3    1 -0.284503      0      0 -0.488580\n",
       "3         1       1    1  0.407697      1      0  0.420494\n",
       "4         0       3    0  0.407697      0      0 -0.486064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('Titanic.csv')\n",
    "df.drop(['PassengerId','Name','Ticket','Cabin',\"Embarked\"],axis=1,inplace=True)\n",
    "df[\"Sex\"]=df['Sex'].map({\"male\":0, \"female\":1}).astype(int)\n",
    "df.head()\n",
    "\n",
    "df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "def Z_norm(col):\n",
    "    return (col-col.mean())/col.std()\n",
    "\n",
    "df['Age']=Z_norm(df['Age'])\n",
    "df['Fare']=Z_norm(df['Fare'])\n",
    "\n",
    "\n",
    "x = df.iloc[:, 1:5]\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412cf860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # Convert y to 1D numpy array if it's not already\n",
    "    y = np.array(y).flatten()\n",
    "    # Use np.bincount for integer labels\n",
    "    proportions = np.bincount(y) / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "\n",
    "def information_gain(X_column, y, threshold):\n",
    "    left_mask = X_column <= threshold\n",
    "    right_mask = X_column > threshold\n",
    "\n",
    "    if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "        return 0\n",
    "\n",
    "    parent_entropy = entropy(y)\n",
    "    n = len(y)\n",
    "    n_left, n_right = len(y[left_mask]), len(y[right_mask])\n",
    "\n",
    "    e_left = entropy(y[left_mask])\n",
    "    e_right = entropy(y[right_mask])\n",
    "\n",
    "    child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "    return parent_entropy - child_entropy\n",
    "\n",
    "# Now you can proceed with the rest of the code as before\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gain = -1\n",
    "    best_feature, best_threshold = None, None\n",
    "\n",
    "    for feature_idx in range(X.shape[1]):\n",
    "        thresholds = np.unique(X.iloc[:, feature_idx].values)\n",
    "        for threshold in thresholds:\n",
    "            gain = information_gain(X.iloc[:, feature_idx].values, y, threshold)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=None):\n",
    "    # Ensure y is a 1D numpy array\n",
    "    y = np.array(y).flatten()\n",
    "\n",
    "    # Base case: if all values are the same or max depth reached\n",
    "    if len(np.unique(y)) == 1 or (max_depth is not None and depth >= max_depth):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    feature, threshold = best_split(X, y)\n",
    "    if feature is None:\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    left_mask = X.iloc[:, feature].values <= threshold\n",
    "    right_mask = X.iloc[:, feature].values > threshold\n",
    "\n",
    "    left_subtree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
    "    right_subtree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
    "\n",
    "    return {\"feature\": feature, \"threshold\": threshold, \"left\": left_subtree, \"right\": right_subtree}\n",
    "\n",
    "def predict_sample(x, tree):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    feature, threshold = tree[\"feature\"], tree[\"threshold\"]\n",
    "    feature_value = x[feature]\n",
    "    if feature_value <= threshold:\n",
    "        return predict_sample(x, tree[\"left\"])\n",
    "    else:\n",
    "        return predict_sample(x, tree[\"right\"])\n",
    "    \n",
    "def predict(x,tree):\n",
    "    return np.array([predict_sample(inp,tree) for inp in x.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acada823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Function for bootstrap sampling\n",
    "def bootstrap_sample(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    X_sample = X.iloc[indices]\n",
    "    y_sample = y.iloc[indices]\n",
    "    return X_sample, y_sample\n",
    "\n",
    "def train_decision_tree(X_train, y_train, max_depth=None):\n",
    "    return build_tree(X_train, y_train, max_depth=max_depth)\n",
    "\n",
    "def predict_with_bagging(X, trees):\n",
    "    predictions = np.array([predict(X, tree) for tree in trees])\n",
    "    return [np.bincount(pred).argmax() for pred in predictions.T]\n",
    "\n",
    "def bagging(X_train, y_train, n_trees=10, max_depth=None):\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        X_sample, y_sample = bootstrap_sample(X_train, y_train)\n",
    "        tree = train_decision_tree(X_sample, y_sample,max_depth)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130bfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging: 82.1229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:, 1:5]\n",
    "y = df.iloc[:, :1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "colls=len(x.columns)-1\n",
    "n_trees = colls**0.5\n",
    "n_trees = int(n_trees)\n",
    "max_depth = 5  \n",
    "trees = bagging(x_train, y_train, n_trees=n_trees, max_depth=max_depth)\n",
    "\n",
    "y_pred = predict_with_bagging(x_test, trees)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test.values.flatten())\n",
    "print(f\"Accuracy with Bagging: {accuracy*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfaf82fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mz:\\3-2\\ML\\ENSEMBLES\\22CSB0B22_BAGGIN.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m y_train\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mwhere(y_train\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m n_estimators\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m classifiers\u001b[39m=\u001b[39madaboost(x_train,y_train,n_estimators)\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m predictions\u001b[39m=\u001b[39madaboost_predict(classifiers, x_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy is \u001b[39m\u001b[39m{\u001b[39;00maccuracy(y_test,predictions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mz:\\3-2\\ML\\ENSEMBLES\\22CSB0B22_BAGGIN.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m classifiers\u001b[39m=\u001b[39m[]\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_estimators):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     stump\u001b[39m=\u001b[39mbuild_stump(X,y,weights)\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     error\u001b[39m=\u001b[39mstump[\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlog((\u001b[39m1\u001b[39m\u001b[39m-\u001b[39merror)\u001b[39m/\u001b[39m\u001b[39mmax\u001b[39m(error, \u001b[39m1e-10\u001b[39m))\n",
      "\u001b[1;32mz:\\3-2\\ML\\ENSEMBLES\\22CSB0B22_BAGGIN.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m min_error\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_features):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     feature_values\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(X[:, feature])\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m feature_values:\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/3-2/ML/ENSEMBLES/22CSB0B22_BAGGIN.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mfor\u001b[39;00m inequality \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mlt\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mgt\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "def build_stump(X,y,weights):\n",
    "    n_samples,n_features=X.shape\n",
    "    best_stump={}\n",
    "    min_error=float('inf')\n",
    "    for feature in range(n_features):\n",
    "        feature_values=np.unique(X[:, feature])\n",
    "        for threshold in feature_values:\n",
    "            for inequality in ['lt','gt']:\n",
    "                predictions=np.ones(n_samples)\n",
    "                if inequality=='lt':\n",
    "                    predictions[X[:,feature]<threshold]=-1\n",
    "                else:\n",
    "                    predictions[X[:,feature]>threshold]=-1\n",
    "                error=sum(weights[predictions!=y])\n",
    "                if error<min_error:\n",
    "                    min_error=error\n",
    "                    best_stump['feature']=feature\n",
    "                    best_stump['threshold']=threshold\n",
    "                    best_stump['inequality']=inequality\n",
    "                    best_stump['error']=error\n",
    "                    best_stump['predictions']=predictions\n",
    "    return best_stump\n",
    "\n",
    "def adaboost(X,y,n_estimators):\n",
    "    n_samples=len(y)\n",
    "    weights=np.ones(n_samples)/n_samples\n",
    "    classifiers=[]\n",
    "    for i in range(n_estimators):\n",
    "        stump=build_stump(X,y,weights)\n",
    "        error=stump['error']\n",
    "        alpha=0.5*np.log((1-error)/max(error, 1e-10))\n",
    "        stump['alpha']=alpha\n",
    "        classifiers.append(stump)\n",
    "        weights*=np.exp(-alpha*y*stump['predictions'])\n",
    "        weights/=sum(weights)\n",
    "    return classifiers\n",
    "\n",
    "def adaboost_predict(classifiers, X):\n",
    "    predictions=np.zeros(X.shape[0])\n",
    "    for classifier in classifiers:\n",
    "        stump_predictions=np.ones(X.shape[0])\n",
    "        feature=classifier['feature']\n",
    "        threshold=classifier['threshold']\n",
    "        inequality=classifier['inequality']\n",
    "        if inequality=='lt':\n",
    "            stump_predictions[X[:,feature]<threshold]=-1\n",
    "        else:\n",
    "            stump_predictions[X[:,feature]>threshold]=-1\n",
    "\n",
    "        predictions+=classifier['alpha']*stump_predictions\n",
    "    return np.sign(predictions)\n",
    "\n",
    "def accuracy(actual,predictions):\n",
    "    correct=0.0\n",
    "    for i in range(len(y_test)):\n",
    "        correct+=(actual[i]==predictions[i])\n",
    "    return correct/float(len(y_test))\n",
    "\n",
    "y_test=np.where(y_test==1,1,-1)\n",
    "y_train=np.where(y_train==1,1,-1)\n",
    "n_estimators=20\n",
    "classifiers=adaboost(x_train,y_train,n_estimators)\n",
    "predictions=adaboost_predict(classifiers, x_test)\n",
    "print(f\"Accuracy is {accuracy(y_test,predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
