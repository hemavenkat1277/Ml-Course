{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bt3222\\AppData\\Local\\Temp\\ipykernel_8812\\2085774198.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.fillna(df.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols= len(df.columns)-1\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns = df.columns\n",
    "length = len(columns) - 1\n",
    "X= df.iloc[:,0:length]\n",
    "Y= df.iloc[:,length]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def entropy(self, data, target_attr):\n",
    "        values = [row[target_attr] for row in data]\n",
    "        counts = Counter(values)\n",
    "        total = len(values)\n",
    "        return -sum((count / total) * math.log2(count / total) for count in counts.values() if count > 0)\n",
    "\n",
    "    def information_gain(self, data, target_attr, attr):\n",
    "        total_entropy = self.entropy(data, target_attr)\n",
    "        values = set(row[attr] for row in data)\n",
    "        subset_entropy = 0\n",
    "        for value in values:\n",
    "            subset = [row for row in data if row[attr] == value]\n",
    "            weight = len(subset) / len(data)\n",
    "            subset_entropy += weight * self.entropy(subset, target_attr)\n",
    "        return total_entropy - subset_entropy\n",
    "\n",
    "    def best_attribute(self, data, attributes, target_attr):\n",
    "        gains = {attr: self.information_gain(data, target_attr, attr) for attr in attributes}\n",
    "        return max(gains, key=gains.get)\n",
    "\n",
    "    def build_tree(self, data, attributes, target_attr):\n",
    "        target_values = [row[target_attr] for row in data]\n",
    "        if len(set(target_values)) == 1:\n",
    "            return target_values[0]\n",
    "        if not attributes:\n",
    "            return Counter(target_values).most_common(1)[0][0]\n",
    "        best_attr = self.best_attribute(data, attributes, target_attr)\n",
    "        tree = {best_attr: {}}\n",
    "        attr_values = set(row[best_attr] for row in data)\n",
    "        for value in attr_values:\n",
    "            subset = [row for row in data if row[best_attr] == value]\n",
    "            if subset:\n",
    "                subtree = self.build_tree(subset, [attr for attr in attributes if attr != best_attr], target_attr)\n",
    "                tree[best_attr][value] = subtree\n",
    "            else:\n",
    "                tree[best_attr][value] = Counter(target_values).most_common(1)[0][0]\n",
    "        return tree\n",
    "\n",
    "    def fit(self, data, target_attr):\n",
    "        attributes = list(data[0].keys())\n",
    "        attributes.remove(target_attr)\n",
    "        self.tree = self.build_tree(data, attributes, target_attr)\n",
    "\n",
    "    def predict(self, sample):\n",
    "        tree = self.tree\n",
    "        while isinstance(tree, dict):\n",
    "            attr = next(iter(tree))\n",
    "            if sample[attr] in tree[attr]:\n",
    "                tree = tree[attr][sample[attr]]\n",
    "            else:\n",
    "                return None\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "None\n",
      "None\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "None\n",
      "None\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "Accuracy : 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset and preprocess\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data = data[['Survived','Embarked', 'Pclass', 'Sex', 'Age']]  # Select relevant features\n",
    "data = data.dropna()\n",
    "\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "data\n",
    "data = data.to_dict(orient='records')\n",
    "target = 'Embarked'\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTree()\n",
    "dt.fit(train_data, target)\n",
    "\n",
    "predictions = [dt.predict(row) for row in test_data]\n",
    "y_true = [row[target] for row in test_data]\n",
    "\n",
    "correct =0\n",
    "for i in predictions:\n",
    "    print(f\"{i}\")\n",
    "    if i == y_true:\n",
    "        correct +=1\n",
    "\n",
    "accuracy = correct/len(y_true)\n",
    "\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1996957016.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[60], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class BaggingDecisionTree:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
